Prework
======

<center><img src="https://imgs.xkcd.com/comics/password_strength.png" width="75%"/></center>

Required
------

- [Visual Information Theory](http://colah.github.io/posts/2015-09-Visual-Information/)
- Khan Academy's [Journey into information theory](https://www.khanacademy.org/computing/computer-science/informationtheory)
- A visual introduction to machine learning
    - [Decision trees](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)
    - [Bias Variance for Decision Trees](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)
- The Basics of Decision Trees 8.1 from [Introduction to Statistical Learning (ISL)](https://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) 
- Decision Trees on [Udacity](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkQXg8TkVdIvYv4HfLG7SiH) 109-169
    - Especially [Entropy Section](https://www.youtube.com/watch?v=Bd15qhUrKCI&index=132&list=PLAwxTw4SYaPkQXg8TkVdIvYv4HfLG7SiH)
 
Optional
------

- [Kullback-Leibler Divergence Explained](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)
- [A Friendly Introduction to Cross-Entropy Loss](http://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)
- Information Theory and Statistics: an overview by Daniel Commenges in readings folder
- Decision trees: an overview and their use in medicine in the readings folder

Challenge
-----

- [Introduction to Information Theory ](https://www.youtube.com/watch?v=BCiZc0n6COY)(1 hour; dry but accurate)
- [IT by Raymond W. Yeung](https://www.youtube.com/watch?v=2Zabhv0aju0&index=3&list=PLJfu_xpF92pvTfcJAILr5Kg1ptMvHUnft)(the best MOOC available)
- Elements of Information Theory by Cover and Thomas    
- [Information Theory: A Tutorial Introduction](http://jim-stone.staff.shef.ac.uk/BookInfoTheory/InfoTheoryBookMain.html) Hands on with code
- [Information Theory, Learning and Big Data Workshop](https://simons.berkeley.edu/workshops/schedule/857)