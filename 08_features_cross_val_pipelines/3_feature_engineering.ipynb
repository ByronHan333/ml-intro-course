{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Feature Engineering</h2></center>\n",
    "\n",
    "<center><img src=\"https://codesachin.files.wordpress.com/2016/06/the-how-and-why-of-feature-engineering-5-638.jpg\" width=\"85%\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By The End Of This Session You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Explain why Feature Engineering (FE) is important\n",
    "- List different common FE methods\n",
    "- Describe the advantages and disadvantages of the common methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/new_oil.jpg\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/refine.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "“data is the fuel of machine learning.” This isn’t quite true: data is like the crude oil of machine learning which means it has to be refined into features — predictor variables — to be useful for training a model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Data is the new Oil:\n",
    "-----\n",
    "\n",
    "- Need high paid experts to derive value\n",
    "- A long, complex, and opaque process to reach useful end state\n",
    "- A history of being taken from people without their permission or benefit\n",
    "- Tends to benefit already rich and powerful companies and nations\n",
    "- Will have long term negative effects on the environment which those companies and nations will not be held accountable for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What is Feature Engineering (FE)?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2> Representing data is the best way possible for a ML algorithm.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2>The process of formulating the most appropriate features given the goal, the algorithm, and the raw data.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why is FE important?\n",
    "------\n",
    "\n",
    "<center><img src=\"images/pipeline.png\" width=\"75%\"/></center>\n",
    "\n",
    "ML algorithms assume digital, numeric inputs.\n",
    "\n",
    "The most valuable information in the world is often not numeric and might not even be digital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Image Source: https://www.safaribooksonline.com/library/view/feature-engineering-for/9781491953235/ch01.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What are the most common data types that are not ML ready?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2>Text & Images</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Brian's experience with matching people to jobs...</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "There is a field of study called \"Measurement Theory\" that studies the limits and proper way to measure/encode information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/succes.jpg\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Feature Engineering is the work of Data Scientists\n",
    "----\n",
    "\n",
    "<center><img src=\"images/Data_Science_VD.png\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    " Source: https://codesachin.wordpress.com/2016/06/25/non-mathematical-feature-engineering-techniques-for-data-science/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Feature Engineering is the work of Data Scientists\n",
    "----\n",
    "\n",
    "- Takes the most time\n",
    "- Has a big impact on modeling and business value\n",
    "- Has not been automated, requires humans and domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://elitedatascience.com/feature-engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3 common approaches to FE\n",
    "-----\n",
    "\n",
    "1. Hand crafted rules\n",
    "2. Learned models\n",
    "3. Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hand crafted rules\n",
    "----\n",
    "\n",
    "A good place to start\n",
    "\n",
    "Very common\n",
    "\n",
    "Requires domain expertise\n",
    "\n",
    "Examples: The \"magic numbers\" in filtering / thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For example, electrical signal processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Learned\n",
    "----\n",
    "\n",
    "Apply ML to Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Typically unsupervised (e.g., dimension reduction or clustering) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In NLP, peform topic modeling (i.e., clustering) then classification within clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Stacking\n",
    "-----\n",
    "\n",
    "<center><img src=\"https://1.bp.blogspot.com/-S8ss-zVfpRM/V1qKcxfCvNI/AAAAAAAAD0I/8UUFyrE4MqQYYuWSxrOOvX3zRfw93nCLwCLcB/s1600/Stacking.png\" width=\"75%\"/></center>\n",
    "\n",
    "The outputs of one model become the inputs of another model\n",
    "\n",
    "`Pipeline = [Transformer, Transformer, Transformer]`\n",
    "\n",
    "More about this next session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are common FE techniques?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Handling Missing Values\n",
    "- Vectorizing\n",
    "- Filtering / Thresholding\n",
    "- Binning\n",
    "- Transforming\n",
    "    - Rescaling \n",
    "- Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Missing Values\n",
    "-----\n",
    "\n",
    "All data has missing values. Just deal with it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Be very careful that the missing data is not systematic of the effect you are studying.\n",
    "\n",
    "Maybe missing data could be a feature (not a bug)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[\"Absence of evidence is not evidence of absence.\"](https://en.wikipedia.org/wiki/Evidence_of_absence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(An incomplete) list of techniques:\n",
    "\n",
    "- Drop rows (instances)\n",
    "- Drop columns (features)\n",
    "- Impute values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ways to impute values\n",
    "-----\n",
    "\n",
    "1. Go get the missing data!\n",
    "1. Sample from existing values \n",
    "1. Calculated mean of existing values\n",
    "1. Fit a model on other features to estimate missing value\n",
    "    - Regression is often used because it is multivariate mean estimation. \n",
    "    - k-NN works well.\n",
    "1. Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://www.theanalysisfactor.com/seven-ways-to-make-up-data-common-methods-to-imputing-missing-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vectorizing\n",
    "-------\n",
    "\n",
    "Categorical (nominal or ordinal) needs to be transformed to a reasonable numbers for ML algorithms to be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Examples of categorical variables: Eye color, Products, Users, Words, …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are the methods to vectorize categorical variables?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One-Hot Encoding \n",
    "- Dummy Coding \n",
    "- Feature Hashing\n",
    "- Bin Counting \n",
    "- Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One-Hot Encoding\n",
    "-----\n",
    "<center><img src=\"images/one.png\" width=\"85%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Feature Hashing, aka hashing trick\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/hash.png\" width=\"75%\"/></center>\n",
    "\n",
    "A hash function is a deterministic function that maps potentially unbounded data to a finite integer range [1, m]. \n",
    "\n",
    "Fit a model on the hash indexes as features. \n",
    "\n",
    "The raw data is vectorized and compressed but loses all interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,  -4., -10.,   0.,   0.,   0.,   0.,   0.,   2.],\n",
       "       [  0.,   0.,   0.,  -2.,  -5.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "h = FeatureHasher(n_features=10)\n",
    "# d = [{'dog': 10,}] # 1 instance & 1 feature\n",
    "# d = [{'dog': 10, 'cat':2, 'elephant':4}] # 1 instance & 3 features\n",
    "d = [{'dog': 10, 'cat':2, 'elephant':4},{'dog': 2, 'run': 5}] # 2 instances\n",
    " \n",
    "f = h.transform(d)\n",
    "\n",
    "f.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Learn more: https://www.youtube.com/watch?v=Uv9dY6Obv-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bin Counting\n",
    "-------\n",
    "\n",
    "<center><img src=\"images/counts.png\" width=\"75%\"/></center>\n",
    "\n",
    "Rather than using the value of the categorical variable as the feature, instead use the __conditional probability of the target under that value__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bin Counting\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/bin_conts.png\" width=\"75%\"/></center>\n",
    "\n",
    "Use probability of click as a feature (not just click or not click).\n",
    "\n",
    "Turns a large, sparse, binary representation of the categorical variable (e.g., one-hot encoding) into a very small, dense, real-valued numeric representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "What is the difference between Bin Counting and Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Naive Bayes always multiplies the conditional probabilities.\n",
    "\n",
    "Bin counting treat them as features, which can be used in other models such as trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Learn more:\n",
    "- https://blogs.technet.microsoft.com/machinelearning/2015/02/17/big-learning-made-easy-with-counts/\n",
    "- https://www.slideshare.net/SessionsEvents/misha-bilenko-principal-researcher-microsoft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Embeddings (e.g., word2vec)\n",
    "----\n",
    "\n",
    "<center><img src=\"https://s3.amazonaws.com/instagram-static/engineering-blog/emoji-hashtags/tsne_map_tight.png\" width=\"30%\"/></center>\n",
    "\n",
    "[Larger version of image](https://s3.amazonaws.com/instagram-static/engineering-blog/emoji-hashtags/tsne_map_tight.png)\n",
    "\n",
    "If you have any sequential discrete data, embedded it. Examples: Words, emojis, website browsing, images, videos, product purchasing …"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://instagram-engineering.com/emojineering-part-1-machine-learning-for-emoji-trendsmachine-learning-for-emoji-trends-7f5f9cb979ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vectorization Methods: Size requirements, growth\n",
    "-----\n",
    "\n",
    "- One-Hot Encoding: k # of categories, grow with new categories\n",
    "- Dummy Coding: k-1 # of categories, grow with new categories\n",
    "- Feature Hashing: _m_ hash table size, fixed\n",
    "- Bin Counting: _m_ bin table size, fixed\n",
    "- Embeddings: _d_ number of dimensions of feature space, fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Filtering / Thresholding\n",
    "------\n",
    "\n",
    "Always perform EDA (especially univariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Remove out-of-bound values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the easiest way to handle out-of-bound values?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Prevent them!\n",
    "\n",
    "Drop down menus are the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Type-ahead is very, very nice\n",
    "\n",
    "<center><img src=\"https://runt-of-the-web.com/wordpress/wp-content/uploads/2017/12/onety-one.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Before type ahead, 20-25% of Google search queries had spelling mistakes.\n",
    "\n",
    "Type-ahead improved the business metrics more than any ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Student Activity\n",
    "-----\n",
    "\n",
    "Remove all negative values from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "palette = \"Dark2\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = [-1, 99, -10, 0, 99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Write both ways: list comprehension and filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99, 0, 99]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in x if _ >= 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0x1a1cde3198>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter(lambda n: n >= 0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99, 0, 99]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda n: n >= 0, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Demo: Bounding values with closures\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def make_bound_func(min_value, max_value):\n",
    "    \"Define a bound function with a certain min and max\"\n",
    "    def bound(value):\n",
    "        \"Limit value between the min and max\"\n",
    "        return min(max_value, max(value, min_value))\n",
    "    return bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bound_rbg = make_bound_func(min_value=0, max_value=255)\n",
    "\n",
    "assert bound_rbg(42) == 42\n",
    "assert bound_rbg(-1) == 0\n",
    "assert bound_rbg(256) == 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from math import inf\n",
    "\n",
    "bound_non_negative = make_bound_func(min_value=0, max_value=inf)\n",
    "\n",
    "assert bound_non_negative(42) == 42\n",
    "assert bound_non_negative(-1) == 0\n",
    "assert bound_non_negative(1_000_000) == 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Defining Outliers / Anomaly Detection\n",
    "------\n",
    "\n",
    "Again, can be done by hand or machine learned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://www.researchgate.net/profile/Mustafa_Aljumaily2/publication/321682378/figure/fig1/AS:569320483033088@1512747988945/Figure-1-anomaly-detection.png\" width=\"50%\"/></center>\n",
    "\n",
    "__2 types of outliers__:\n",
    "\n",
    "1. Generated by the same statistical process as your data (just unusual spread)\n",
    "2. Generated by a __different__ statistical process as your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Binning, aka Quantization \n",
    "-----\n",
    "\n",
    "<center><img src=\"https://i.stack.imgur.com/XNIQd.jpg\" width=\"75%\"/></center>\n",
    "\n",
    "Discretize continuous values into a smaller number of \"bins\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why would you purposely lose information by downsampling your data?\n",
    " -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. It makes sense for your goal (e.g., categorize people's age by decade)\n",
    "1. Improve signal-to-noise ratio (e.g., GPS data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Fitting a model to bins reduces the impact that small fluctuates in the data has on the model, often small fluctuates are just noise. Each bin \"smooths\" out the fluctuates/noises in sections of the data.\n",
    "\n",
    "Source: https://datascience.stackexchange.com/questions/19782/what-is-the-rationale-for-discretization-of-continuous-features-and-when-should/23860#23860"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Transforming\n",
    "----\n",
    "\n",
    "- Linear: \n",
    "    - Most commonly each data value is added or multiplied by the same constant\n",
    "    - Example: Normalization & Standardization\n",
    "    - Generally fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Linear preserves the operations of addition and scalar multiplication\n",
    "\n",
    "Learn more: https://en.wikipedia.org/wiki/Linear_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Nonlinear:\n",
    "    - Mostly commonly each data value is added or multiplied by a different value\n",
    "    - Examples: Squaring each value\n",
    "    - \"With great power, comes great responsibility\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Nonlinear does __NOT__ preserves the operations of addition and scalar multiplication "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Rescaling\n",
    "------\n",
    "\n",
    "Often features are orders of magnitude different from each other.\n",
    "\n",
    "Several ML algorithms are sensitive to feature scaling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://stats.stackexchange.com/questions/244507/what-algorithms-need-feature-scaling-beside-from-svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "Which specific algorithms are sensitive to feature scaling?\n",
    "\n",
    "What is common among them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "k-NN, SVM, and neural networks are sensitive to feature transformations.\n",
    "\n",
    "They exploit distances or similarities between data samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Naive Bayes (a graphical model) and  Tree-based models learn features independently.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What's the difference between Normalization and Standardization?\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Normalization, aka min-max scaling\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/min_max.png\" width=\"65%\"/></center>\n",
    "\n",
    "Rescales the values into a range of [0,1].  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Normalization, aka min-max scaling\n",
    "-----\n",
    "\n",
    "Useful where all values need to be on the same positive scale. \n",
    "\n",
    "However, the outliers from the data set are compressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Standardization, aka variance scaling\n",
    "-------\n",
    "\n",
    "Rescales data to have a mean ($\\mu$) of 0 and standard deviation ($\\sigma$) of 1 (unit variance).\n",
    "\n",
    "$$ X_{changed} = \\frac{X - \\mu}{\\sigma} $$        \n",
    "\n",
    "Retains outlier values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "\n",
    "Source: https://stats.stackexchange.com/questions/10289/whats-the-difference-between-normalization-and-standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Student Activity\n",
    "------\n",
    "\n",
    "Write a normalization function.\n",
    "\n",
    "$$ X_{changed} = \\frac{X - X_{min}}{X_{max}-X_{min}} $$ \n",
    "\n",
    "Bonus points if you write a generalized rescaling function (e.g., given a set of value rescale them to be between a any new min and max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def rescale(nums, new_min=0, new_max=1):\n",
    "    \"Rescale values to be rescaled between new min and max\"\n",
    "    return [(new_max - new_min) / (max(nums)-min(nums)) * (value-max(nums)) + new_max for value in nums]\n",
    "\n",
    "nums = list(range(-99, 100))\n",
    "assert int(min(rescale(nums))) == 0 \n",
    "assert int(max(rescale(nums))) == 1\n",
    "assert int(min(rescale(nums, new_min=-1, new_max=1))) == -1\n",
    "assert int(max(rescale(nums, new_min=-1, new_max=1))) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Always use the best available library\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() # Let's look at the docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89908257]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(np.array(x).reshape(-1, 1))\n",
    "scaler.transform(np.array([88]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Feature Selection: What is one way to remove uninformative features?\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2> L1 regularization</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://i.stack.imgur.com/7YKyum.png\" width=\"55%\"/></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <center><img src=\"https://i.stack.imgur.com/59fltm.png\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    " Source: https://stats.stackexchange.com/questions/74542/why-does-the-lasso-provide-variable-selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Feature Selection Methods\n",
    "-----\n",
    "\n",
    "1. Filtering\n",
    "1. Wrapper methods\n",
    "1. Embedded methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "scikit-learn's `feature_selection` module\n",
    "-----\n",
    "\n",
    "Let's take a look [https://scikit-learn.org/stable/modules/feature_selection.html](https://scikit-learn.org/stable/modules/feature_selection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DL Does Automatic Feature Learning\n",
    "------\n",
    "\n",
    "<center><img src=\"http://adilmoujahid.com/images/traditional-ml-deep-learning-2.png\" width=\"1500\"/></center>\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: http://adilmoujahid.com/posts/2016/06/introduction-deep-learning-python-caffe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "------\n",
    "\n",
    "- Feature Engineering (FE) might have bigger impact than algorithm selection and model tuning\n",
    "- FE is impactive when working in new domains, especially ones that are not digital native.\n",
    "- The goal of FE is change the raw data to best possible feature for a ML algorithm.\n",
    "- It is both an art (heuristic based) and a science (systematic and can use ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
