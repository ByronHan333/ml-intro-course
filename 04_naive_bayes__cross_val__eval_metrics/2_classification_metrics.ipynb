{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Classification Metrics\n",
    "---\n",
    "<center><img src=\"https://i.pinimg.com/736x/18/c0/36/18c036f262ef322194553462279e5bbf.jpg\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why do care about evaluation metrics?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Evaluation metrics help select better, aka more useful, models.\n",
    "\n",
    "Are these good parameter estimates?     \n",
    "Which hyperparamters are better?   \n",
    "Which algorithm should we use?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are common evaluation metrics for regression?\n",
    "-----\n",
    "\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are common evaluation metrics for classification?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Accuracy \n",
    "- Recall\n",
    "- Precision\n",
    "- F-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By the end of this session, you should be able to:\n",
    "---\n",
    "\n",
    "- List common classification metrics\n",
    "- Explain the limitations of accuracy as a metric\n",
    "- Construct a confusion matrix\n",
    "- Extend confusion matrix beyond binary classification\n",
    "- Define precision, recall, and F score\n",
    "- Draw and explain a ROC curve\n",
    "- Define AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Accuracy\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$Accuracy = \\frac{All\\ Correct}{Total}$$\n",
    "\n",
    "- Fraction of observations classified correctly\n",
    "- 1 - error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the biggest limitation of accuracy?\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Accuracy is an overall measure (ignores which classes were correctly predicted). It does not tell you what \"types\" of errors your classifier is making\n",
    "\n",
    "\n",
    "It is effected by class imbalances, when there is much one group than another group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Null Accuracy\n",
    "-------\n",
    "\n",
    "Accuracy that could be achieved by always predicting the most frequent class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for Understanding\n",
    "-----\n",
    "\n",
    "Draw a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Confusion Matrix\n",
    "------\n",
    "\n",
    "<center><img src=\"http://i.stack.imgur.com/ysM0Z.png\" width=\"40%\"/></center>\n",
    "\n",
    "- True Positives (TP): correctly predicted a succesfull outcome /  one \n",
    "label \n",
    "- True Negatives (TN): correctly predicted a lack of an outcome / other label \n",
    "- False Positives (FP): incorrectly predicted a succesfull outcome (a \"Type I error\")\n",
    "- False Negatives (FN): incorrectly predicted lack of an outcome (a \"Type II error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://chemicalstatistician.files.wordpress.com/2014/05/pregnant.jpg?w=500\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's classify movies as \"RomCom\" or not...\n",
    "------\n",
    "\n",
    "<center><img src=\"images/rom1.png\" width=\"45%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Extension beyond 2 groups\n",
    "---\n",
    "\n",
    "<center><img src=\"images/rom2.png\" width=\"45%\"/></center>\n",
    "\n",
    "The classifier is misclassifying movies as Comedy when they are RomCom more often than Drama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is always important to look at the confusion matrix to analyze your results as it also gives you very strong clues as to where your classifier is going wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "----\n",
    "\n",
    "How does confusion matrix scale as a function of the number of classes (k)?\n",
    "\n",
    "If there are 10 classes, how many cells does the confusion matrix have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Number of Classes -> Number of Cells \n",
    "------\n",
    "\n",
    "- 2 -> 4\n",
    "- 3 -> 9\n",
    "- 4 -> 15\n",
    "- …\n",
    "- 10 -> 100\n",
    "\n",
    "The number of cells in a confusion matrix scale is __k<sup>2</sup>__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://www.bluemontlabs.com/images/statistical-classification-metrics.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/roc.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://www.info.univ-angers.fr/~gh/Predipath/confus1.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Precision\n",
    "------\n",
    "\n",
    "$$Precision = \\frac{Class\\ Correct}{Class\\ Total\\ Predicted}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Fraction of labeled items assigned to a class that are actually members of that class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall\n",
    "-----\n",
    "\n",
    "$$Recall = \\frac{Class\\ Correct}{Class\\ Total\\ Actual}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Fraction of labeled items in a class that are classified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Example\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/results.png\" width=\"85%\"/></center>\n",
    "\n",
    "The data is the labeled ground truth.\n",
    "\n",
    "Let's compare models: 1 vs 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/results.png\" width=\"85%\"/></center>\n",
    "\n",
    "What is the baserate for red?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "20% (2 reds out of 10 total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/results.png\" width=\"85%\"/></center>\n",
    "\n",
    "What is the accuracy of Model 1? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "80% accurate \n",
    "\n",
    "Model 1 predicts all blue and gets all the blue dots correct. Misses the 2 reds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/results.png\" width=\"85%\"/></center>\n",
    "\n",
    "What is the recall of Model 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each class should be calculated separately!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "0% recall for red. The model fails to label any true red as red.  \n",
    "100% recall for blue. The model labels all true blues as blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "You can also weight recall for multi-class classification. Read more [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/results.png\" width=\"85%\"/></center>\n",
    "\n",
    "What is the accuracy of Model 2? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "70% accurate  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/results.png\" width=\"85%\"/></center>\n",
    "\n",
    "What is the recall of Model 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "100% recall for red. The model labels all true red as red.   \n",
    "75% recall for blue. The model labels 6 out 8 possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/results.png\" width=\"85%\"/></center>\n",
    "\n",
    "Which model would you deploy into production?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Extending to more than 2 groups\n",
    "------\n",
    "<center><img src=\"images/p_r.png\" width=\"90%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ROC (receiver operating characteristic) curve \n",
    "----\n",
    "<center><img src=\"images/roc_first.png\" width=\"50%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ROC curve & Thresholds\n",
    "----\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/ROC_curves.svg/300px-ROC_curves.svg.png\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ROC curve to compare models\n",
    "----\n",
    "\n",
    "<center><img src=\"images/roc_2.png\" width=\"65%\"/></center>\n",
    "\n",
    "Model A is strictly better than Model B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ROC curve to compare models\n",
    "----\n",
    "\n",
    "<center><img src=\"images/Roccurves.png\" width=\"50%\"/></center>\n",
    "\n",
    "IRL, some models will do better at different thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "AUC: Area Under the Curve\n",
    "-----\n",
    "\n",
    "<center><img src=\"https://i.stack.imgur.com/9NpXJ.png\" width=\"55%\"/></center>\n",
    "\n",
    "A single metric to combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "What is AUC for random guessing a binary classifier with even base rates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the highest possible AUC? What does the ROC curve look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "F<sub>1</sub> score\n",
    "-----\n",
    "\n",
    "$$F_1\\ Score = 2•\\frac{Precision•Recall}{Precision+Recall}$$\n",
    "\n",
    "A single metric that combines precision and recall.\n",
    "\n",
    "In Machine Learning, we want a single metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Generalized F score\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/f_score_2.png\" width=\"75%\"/></center>\n",
    "\n",
    "F<sub>1</sub> weighs recall and precision equally.\n",
    "\n",
    "F<sub>0.5</sub> weighs recall lower than precision (by reducing the influence of false negatives).\n",
    "\n",
    "F<sub>2</sub> weighs recall higher than precision (by placing more emphasis on false negatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Which metrics should you focus on?\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choice of metric depends on your business objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can define custom evaluaton mertrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "airbnb custom metrics\n",
    "------\n",
    "<center><img src=\"https://adriancolyer.files.wordpress.com/2018/09/airbnb-fig-4.jpeg?w=480\" width=\"55%\"/></center>\n",
    "<center><img src=\"https://adriancolyer.files.wordpress.com/2018/09/airbnb-fig-7.jpeg?w=480\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://blog.acolyer.org/2018/10/03/customized-regression-model-for-airbnb-dynamic-pricing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary, part I\n",
    "---\n",
    "\n",
    "- The most common classification metrics:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F-score\n",
    "- Accuracy is not accurate if there are class imbalances. In real DS, there are __always__ class imbalances.\n",
    "- A confusion matrix is an awesome way to visualize error types.\n",
    "- Confusion matrices can be extend to multinomial classification.\n",
    "- Brian ♥️s confusion matrices so always bring him one when asking for advice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary, part II\n",
    "---\n",
    "\n",
    "- Precision measures if a classifier has right labels.\n",
    "- Recall measures if a classifier does not miss a label.\n",
    "- F score combines precision and recall.\n",
    "- A ROC curve visualizes how changing a threshold impacts model performance.\n",
    "- AUC is the area under the ROC curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/break.png\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bonus Material\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Precision recall curves\n",
    "-----\n",
    "\n",
    "![](images/pr.png)\n",
    "\n",
    "Precision vs recall as we vary the threshold τ.\n",
    "\n",
    "This curve can be summarized as a single number using the mean precision (averaging over recall values), which approximates the area under the curve. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
