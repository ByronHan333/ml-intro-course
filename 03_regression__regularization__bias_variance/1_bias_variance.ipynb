{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Bias & Variance in Machine Learning Models</h2></center>\n",
    "\n",
    "<center><img src=\"https://cdn-images-1.medium.com/max/1600/1*xfIbyKKMDmjQF9JFuK2Ykg.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By The End Of This Session You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Define bias and variance in your own words\n",
    "- Identify and correct examples of bias and variance problems\n",
    "- Explain the bias–variance tradeoff "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What We Talk About When We Talk About Bias\n",
    "------\n",
    "\n",
    "We are only discussing technical bias in predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### NOT:\n",
    "\n",
    "- Human / Cognitive  biases\n",
    "- Fairness "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From last class, what is a model?\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The end result of a general Machine Learning algorithm.\n",
    "\n",
    "A specific architecture and a specific set of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is Bias in ML?\n",
    "------\n",
    "\n",
    "Bias is the error rate of your model on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Bias is how much your model __under-fits__ the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "High Bias in Regression: Just an Intercept Model\n",
    "-----\n",
    "<center><img src=\"images/intercept.png\" width=\"35%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you compute bias?\n",
    "-------\n",
    "\n",
    "<center><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/2b2080ebdc7a908f7cecdfa6540dd45600b24bf3\" width=\"75%\"/></center>\n",
    "\n",
    "Expected difference between predicted and observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "An algorithm that has a good ability to fit the training data has \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ bias.   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{high, low} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An algorithm that has a good ability to fit the training data has __low__ bias.\n",
    "\n",
    "Bias is a bad thing, we want to minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two Types of Errors on Training Datasets\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/ir_error.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where do irreducible errors come from?\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/error_types.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bayes Error: Irreducible error in classification\n",
    "---------\n",
    "\n",
    "<center><img src=\"images/bayes.png\" width=\"55%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://kevinzakka.github.io/assets/app_dl/perf.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias is a learners' tendency to learn the wrong thing\n",
    "-----    \n",
    "\n",
    "Which the following has higher bias?\n",
    "\n",
    "1. $y = \\beta _0$\n",
    "1. $y = \\beta _0 + \\beta _1x $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$y = \\beta _0$ \n",
    "\n",
    "Has a more limited ability to learn the correct thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the one weird trick in decrease bias?\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make the model more complex!  \n",
    "$y = \\beta _0 + \\beta _1x $  \n",
    "$y = \\beta _0 + \\beta _1x  + \\beta _2x$  \n",
    "$y = \\beta _0 + \\beta _1x  + \\beta _2x + \\beta _3x$  \n",
    "…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "or use a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " or use a random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " or use Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2> Increasing the complexity/size of the model, will always better fit the training data set*</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "What is the only case when increasing the complexity/size of the model, will *not* increase fit the training data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When your model perfectly fits the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2> Bias is error from erroneous assumptions in the algorithm.</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which type of models are most likely to erroneous assumptions?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Parametric models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Algorithms with high bias \n",
    "-------\n",
    "\n",
    "- Produce simple models\n",
    "- Fail to capture important regularities in the data\n",
    "- Under-fit their training data (also don't over-fit either)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias in the world of Big Data\n",
    "------\n",
    "\n",
    "As a working Big Data Scientist, bias is the error rate when you have a lot of data.\n",
    "\n",
    "\n",
    "You fit the training set as well as possible with a given algorithm but it still makes errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "You have a reasonable algorithm (e.g., random forest) but still have high bias. What should you do with features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Larger set of features\n",
    "- Better features\n",
    "\n",
    "Both will increase your model's ability to fit the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Any questions before moving onto variance?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is Variance in ML?\n",
    "------\n",
    "\n",
    "Variance is the amount that an algorithm's model will change if a different training data is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Variance is an algorithm's tendency to learn random things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Variance is much your model __over-fits__ the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "High Variance in Regression: Polynomials\n",
    "-------\n",
    "\n",
    "<center><img src=\"https://onlinecourses.science.psu.edu/stat857/sites/onlinecourses.science.psu.edu.stat857/files/lesson03/d15_polynomial/index.gif\" width=\"65%\"/></center>\n",
    "\n",
    "A method has high variance if small changes in the training data can result in large changes in the estimated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you compute variance?\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " <center><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/d0b6567c3e17811e91792be7d13b1521d6fc0adc\" width=\"75%\"/></center>\n",
    "\n",
    "Intuitively, how much the algorithm will move around its mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "An algorithm that is strongly influenced by the specifics of the training data has \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ variance.   \n",
    "{high, low} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An algorithm that is strongly influenced by the specifics of the training data __high__ variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, decision trees tend to change their predicted values for training sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Model Complexity will Increase Variance \n",
    "------\n",
    "\n",
    "The more complex the model is, the more data points it will \"capture\". \n",
    "\n",
    "However, complexity will make the model \"move\" more to \"capture\" the data points, and hence its variance will be larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Big Trouble with High Variance\n",
    "-------\n",
    "\n",
    "Can cause overfitting, modeling the random noise in the training data, rather than the intended outputs.\n",
    "\n",
    "High variance can cause an algorithm to model the random noise in the training data, rather than the intended outputs (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "Which will have higher variance parametric models or nonparametric models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generally, nonparametric machine learning algorithms have more flexibility, thus high variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "You have a reasonable algorithm (e.g., Logistic Regression) but still have high variance. What can you do with features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Smaller set of features\n",
    "\n",
    "Hence, regularization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Data is the world's best regularizer</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A larger training set tends to decrease variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reduce the chance of overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Increase the chance of generalization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Calculating Variance: \"That is an empirical question\"\n",
    "-----\n",
    "\n",
    "Variance is how much worse you do on the test dataset compared to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Assuming:\n",
    "\n",
    "- You have reasonable amount of data\n",
    "- You do not have a ridiculously complex model (combination of flexible algorithm and a lot of features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What should you do if you have high variance?\n",
    "------\n",
    "\n",
    "1. Bagging methods (e.g., Random Forest)\n",
    "1. Feature Selection\n",
    "1. Regularization\n",
    "1. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Any questions before moving onto bias-variance tradeoff?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias-variance trade-off\n",
    "------\n",
    "\n",
    "<center><img src=\"https://i.stack.imgur.com/alkeM.png\" width=\"75%\"/></center>\n",
    "\n",
    "The problem of simultaneously minimizing two sources of error that prevent supervised learning algorithms from generalizing beyond their training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://www.luigifreda.com/wp-content/uploads/2017/03/Bias-Variance-Tradeoff-660x445.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The goal of Machine Learning:\n",
    "\n",
    "1. Low bias (model the  patterns in the observed data) \n",
    "1. Low variance (not sensitive to specificities of the observed data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://pseudotitle.files.wordpress.com/2016/12/bias-variance-decomposition.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias-variance trade-off in Regression\n",
    "------\n",
    "\n",
    "<center><img src=\"https://codesachin.files.wordpress.com/2015/08/plot_bias_variance_examples_31.png\" width=\"65%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias-variance trade-off: A balancing act\n",
    "------\n",
    "\n",
    "<center><img src=\"images/abstract_better.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Empirical trick: How do actually use this trade-off?\n",
    "------\n",
    "\n",
    "\n",
    "You want to fit a model that does really well on training set (low bias) and well on unseen data (low variance).\n",
    "\n",
    "1. Collect a lot of data\n",
    "1. Engineer good features\n",
    "1. Pick a complex algorithm\n",
    "1. Train the specific model until validation scores starts to go down (smart early stopping).\n",
    "1. Stop if model meets service level agreement (SLA). Otherwise go back to 1.\n",
    "\n",
    "You'll have minimal bias while minimizing variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "What does this curve imply? High Variance, High Bias\n",
    "\n",
    "<center><img src=\"images/high_bias.png\" width=\"75%\"/></center>\n",
    "\n",
    "Think, Pair, Share"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/high_bias.png\" width=\"75%\"/></center>\n",
    "\n",
    "High Bias: Your training error is way higher than desired performance!   \n",
    "Low Variance: Small gap between training and test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "------\n",
    "\n",
    "- Bias is the error rate of your model on the training dataset.\n",
    "- Variance is amount of change in your model based on the training dataset.\n",
    "- We want low bias (fit the trianing set) and low variance (fit other datasets)\n",
    "- Often we have to trade lower bias for higher variance as models increase in complexity.\n",
    "- More (and cleaner) data always helps. \n",
    "- Better features sometimes helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bonus Material\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/abstract.png\" width=\"75%\"/></center> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
